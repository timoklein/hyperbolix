# Hyperbolix JAX Migration - Project Handoff

## Current Status

**Phase 1 (Manifolds) âœ…** | **Phase 2 (Optimizers) ðŸš§** | **Phase 3a & 3b (NN Layers) âœ…** | **Idiomatic JAX Refactor âœ…** | **CI/Tooling âœ…**

### Test Results
- **Manifolds**: 978 passing, 72 skipped (100% non-skipped)
- **NN Layers**: 44/44 passing (100%)
- **Hyperboloid Convolution**: 44/44 passing (100%)
- **Math Utils**: 8/8 passing (100%)
- **Helper Utils**: 38/38 passing (100%)
- **HoroPCA**: 25/25 passing (100%)
- **Optimizers**: 15/20 passing (75%) - 5 multi-parameter tests need tree handling fix
- **Benchmarks**: 168 test cases passing (100%)

---

## What's Complete

### Phase 1: Core Geometry (Manifolds)

**Location**: `src/hyperbolix_jax/manifolds/`

**Implemented**:
- âœ… `euclidean.py` - Flat Euclidean space
- âœ… `poincare.py` - PoincarÃ© ball with MÃ¶bius operations
- âœ… `hyperboloid.py` - Hyperboloid with Lorentz/Minkowski geometry
- âœ… `*_checked.py` - Checkify error handling modules for all manifolds

**API**:
- Pure functional design (no classes, no state)
- vmap-native API: functions operate on single points, no `axis`/`keepdim` parameters
- Integer version indices with `lax.switch` for JIT optimization
- Operations: proj, addition, scalar_mul, dist, expmap, logmap, retraction, ptransp, tangent operations, egrad2rgrad, validation

**Math Utilities** (`src/hyperbolix_jax/utils/math_utils.py`):
- âœ… JIT-compiled hyperbolic functions (cosh, sinh, acosh, atanh)
- âœ… Numerically stable smooth clamping with static `smoothing_factor`

**Helper Utilities** (`src/hyperbolix_jax/utils/helpers.py`):
- âœ… `compute_pairwise_distances`: Efficient pairwise distance computation using vmap
- âœ… `compute_hyperbolic_delta`: Delta-hyperbolicity metric based on Gromov 4-point condition
- âœ… `get_delta`: Combined delta, diameter, and relative delta computation with subsampling

**HoroPCA** (`src/hyperbolix_jax/utils/horo_pca.py`):
- âœ… `compute_frechet_mean`: Gradient descent FrÃ©chet mean on hyperboloid
- âœ… `center_data`: Lorentz transformation centering via Lorentz boost
- âœ… `HoroPCA`: Flax NNX module for hyperbolic dimensionality reduction via horospherical projections
- âœ… Supports PoincarÃ© & Hyperboloid manifolds, rank-1 special case, pinv for stability

### Phase 3a: Linear Neural Network Layers

**Location**: `src/hyperbolix_jax/nn_layers/`

**Implemented**:
- âœ… Standard layers: Expmap, Logmap, Proj, TanProj, Retraction, HyperbolicActivation
- âœ… PoincarÃ©: HypLinearPoincare, HypLinearPoincarePP
- âœ… Hyperboloid: HypLinearHyperboloid, FHNN, FHCNN variants
- âœ… Hyperboloid Convolution: HypConvHyperboloid with Lorentz direct concatenation (HCat)

**Architecture**: Flax NNX modules storing manifold module references, curvature `c` passed at call time

### Phase 3b: Regression Neural Network Layers

**Implemented**:
- âœ… PoincarÃ©: HypRegressionPoincare, HypRegressionPoincarePP
- âœ… Hyperboloid: HypRegressionHyperboloid
- âœ… RL: HypRegressionPoincareHDRL (standard & rs versions)
- âœ… Helpers: compute_mlr_poincare_pp, compute_mlr_hyperboloid, safe_conformal_factor

### Phase 2: Riemannian Optimizers ðŸš§

**Location**: `src/hyperbolix_jax/optim/`

**Implemented**:
- âœ… `manifold_metadata.py` - Metadata system using NNX Variable._var_metadata
- âœ… `riemannian_sgd.py` - RSGD with momentum & parallel transport
- âœ… `riemannian_adam.py` - RAdam with adaptive rates & moment transport
- âœ… Layer annotations: HypLinearPoincare, HypRegressionPoincare bias marked as manifold params
- âœ… Multi-parameter pytree handling & PyTorch-style second-moment accumulation (all tests green)

**Architecture**: Standard Optax GradientTransformation, automatic manifold detection, supports expmap/retraction modes

---

## Recent Improvements

### Idiomatic JAX Refactor (2025-10-09)
- âœ… vmap-native API: All manifolds refactored to single-point operations
- âœ… `lax.switch` for version selection with integer indices
- âœ… `jnp.finfo(x.dtype)` for dtype-aware epsilon
- âœ… Checkify modules for runtime validation
- âœ… NN layers updated: assertions in `__init__`, vmap API

### CI & Tooling Hardening (2025-10-16)
- âœ… CI pipeline: split into lint, type-check, test matrix (4 parallel suites), benchmark jobs
- âœ… Pre-commit hooks: Ruff linting/formatting, YAML/TOML validation, merge conflict detection
- âœ… Pyright type checking: configured for `src/hyperbolix_jax` with Python 3.12+ syntax
- âœ… JIT benchmarks: 168 parametrized tests across manifolds & NN layers
- âœ… Benchmark regression detection: fails on >10% slowdown
- âœ… Legacy code modernized: built-in generics, f-strings, Python 3.12+

### Developer Workflow (2025-10-15)
- âœ… Pre-commit: automatic formatting & validation
- âœ… DEVELOPER_GUIDE.md with comprehensive workflow reference
- âœ… benchmarks/README.md with usage guide
- âœ… UV dependency caching for faster CI

---

## Architecture

### Pure Functional Design
```python
# Old PyTorch (stateful class)
manifold = Hyperboloid(c=1.0)
result = manifold.dist(x, y)

# New JAX (pure functions, vmap-native)
import hyperbolix_jax.manifolds.hyperboloid as hyperboloid
result = hyperboloid.dist(x, y, c=1.0)  # (dim,) -> scalar
```

### NN Layer Pattern
```python
class HypLinearPoincare(nnx.Module):
    def __init__(self, manifold_module, in_dim, out_dim, *, rngs):
        self.manifold = manifold_module
        self.weight = nnx.Param(...)
        self.bias = nnx.Param(...)

    def __call__(self, x, c=1.0):  # x: (batch, in_dim)
        # Forward pass with manifold operations
        ...
```

---

## Test Commands

```bash
# Run all JAX tests
uv run pytest tests/jax/ -v

# Run specific test suites
uv run pytest tests/jax/test_manifolds.py -v
uv run pytest tests/jax/test_nn_layers.py -v
uv run pytest tests/jax/test_regression_layers.py -v

# Run benchmarks
uv run pytest benchmarks/ -v

# Run pre-commit checks
uv run pre-commit run --all-files
```

---

## Key Files

### Manifolds
- `src/hyperbolix_jax/manifolds/{euclidean,poincare,hyperboloid}.py` (includes `hcat` in hyperboloid)
- `src/hyperbolix_jax/manifolds/{euclidean,poincare,hyperboloid}_checked.py`
- `src/hyperbolix_jax/utils/math_utils.py`
- `src/hyperbolix_jax/utils/helpers.py`

### NN Layers
- `src/hyperbolix_jax/nn_layers/standard_layers.py`
- `src/hyperbolix_jax/nn_layers/{poincare,hyperboloid}_linear.py`
- `src/hyperbolix_jax/nn_layers/hyperboloid_conv.py` - Hyperboloid convolution with HCat
- `src/hyperbolix_jax/nn_layers/{poincare,hyperboloid}_regression.py`
- `src/hyperbolix_jax/nn_layers/poincare_rl.py`
- `src/hyperbolix_jax/nn_layers/helpers.py`

### Optimizers
- `src/hyperbolix_jax/optim/manifold_metadata.py`
- `src/hyperbolix_jax/optim/riemannian_{sgd,adam}.py`
- `OPTIMIZER_PLAN.md` - Design document

### Tests
- `tests/jax/test_manifolds.py` (912 parametrized tests)
- `tests/jax/test_nn_layers.py` (22 tests)
- `tests/jax/test_hyperboloid_conv.py` (44 tests: HCat operation + conv layer)
- `tests/jax/test_regression_layers.py` (22 tests)
- `tests/jax/test_optimizers.py` (20/20 passing; covers metadata, mixed params, NNX integration)
- `tests/jax/test_math_utils.py` (8 tests)
- `tests/jax/test_helpers.py` (38 tests)
- `tests/jax/test_horo_pca.py` (25 tests: FrÃ©chet mean, centering, fit/transform, rank-1)

### Documentation
- `DEVELOPER_GUIDE.md` - Development workflow
- `benchmarks/README.md` - Benchmark usage
- `.github/workflows/ci.yaml` - CI pipeline
- `pyproject.toml` - Project config, Pyright settings

---

## Next Steps

1. **End-to-end examples** - Training loops demonstrating JAX/NNX usage
2. **Documentation** - API docs, usage examples, JIT best practices

## Known Issues

- None currently tracked for optimizers; flag new regressions in CI.

## Edge Cases & Considerations

### Hyperboloid Convolutional Layer

1. **Padding Strategy**
   - Uses `mode="edge"` (replicates border pixels) instead of zero-padding
   - **Rationale**: Zero vectors don't lie on the hyperboloid manifold; edge replication preserves valid manifold points
   - **Implication**: Different behavior from standard Euclidean CNNs at boundaries

2. **Dimensional Growth in Multi-Layer Architectures**
   - HCat operation increases dimensionality: input ambient dim `d+1` â†’ output ambient dim `(dÃ—N)+1` where `N = kernel_h Ã— kernel_w`
   - **Example**: 3-dim input with 3Ã—3 kernel â†’ 3Ã—9+1 = 28-dim output
   - **Implication**: Dimension grows rapidly in deep networks; consider small kernels (1Ã—1, 2Ã—2) or dimensionality reduction between layers

3. **Numerical Stability in HCat**
   - Formula: `sqrt(sum(x_i[0]^2) - (N-1)/c)` requires `sum(x_i[0]^2) â‰¥ (N-1)/c`
   - **Valid for**: Properly initialized hyperboloid points where `x[0] â‰¥ 1/sqrt(c)`
   - **Risk**: Low under normal conditions; NaN possible with invalid inputs or extreme curvatures
   - **Mitigation**: Input validation via `is_in_manifold` checks

4. **Jaxtyping Annotations**
   - Ruff linter reports F722/F821 errors on shape specifications (`"N n"`, `"dim_plus_1"`, etc.)
   - **Status**: False positives - jaxtyping uses string literals for runtime shape checking
   - **Action**: Ignore these specific Ruff errors; pattern used consistently throughout codebase
